sudo docker run -it --rm --gpus all --network=host --ipc=host --ulimit memlock=-1 --ulimit stack=67108864 -v ~/models:/models --env HUGGINGFACE_HUB_CACHE=/workspace --env "YOUR_KEY_HERE" az:nvidia-575.trtllm.0.2.0r1

sudo docker run -it --rm --gpus all --network=host --ipc=host --ulimit memlock=-1 --ulimit stack=67108864 -v ~/models:/models --env HUGGINGFACE_HUB_CACHE=/workspace --env "YOUR_KEY_HERE" az:nvidia-575.trtllm.0.2.0r1 python3 trtllm-serve /models/Llama-3.3-70B-Instruct-FP4 --backend pytorch --host 0.0.0.

sudo docker run -it --rm --gpus all --network=host --ipc=host --ulimit memlock=-1 --ulimit stack=67108864 -v ~/models:/models --env HUGGINGFACE_HUB_CACHE=/workspace --env "YOUR_KEY_HERE" az:nvidia-575.vllm.0.9.0b python3 -m vllm.entrypoints.openai.api_server  --model /models/Qwen-Qwen3-8B-FP8     --max-model-len 8192     --served-model-name Qwen-Qwen3-8B-FP8

NVFP4--Qwen3-Coder-30B-A3B-Instruct-FP4

sudo docker run -it --rm --gpus all --network=host --ipc=host --ulimit memlock=-1 --ulimit stack=67108864 -v ~/models:/models --env HUGGINGFACE_HUB_CACHE=/workspace --env "YOUR_KEY_HERE" az:nvidia-575.vllm.0.9.0b python3 -m vllm.entrypoints.openai.api_server  --model /models/NVFP4--Qwen3-Coder-30B-A3B-Instruct-FP4     --max-model-len 8192     --served-model-name NVFP4--Qwen3-Coder-30B-A3B-Instruct-FP4

Qwen3-Coder-30B-A3B-Instruct-FP8

sudo docker run -it --rm --gpus all --network=host --ipc=host --ulimit memlock=-1 --ulimit stack=67108864 -v ~/models:/models --env HUGGINGFACE_HUB_CACHE=/workspace --env "YOUR_KEY_HERE" az:nvidia-575.vllm.0.9.0b python3 -m vllm.entrypoints.openai.api_server  --model /models/Qwen3-Coder-30B-A3B-Instruct-FP8     --max-model-len 8192     --served-model-name Qwen3-Coder-30B-A3B-Instruct-FP8

Qwen-Qwen3-32B-FP8

sudo docker run -it --rm --gpus all --network=host --ipc=host --ulimit memlock=-1 --ulimit stack=67108864 -v ~/models:/models --env HUGGINGFACE_HUB_CACHE=/workspace --env "YOUR_KEY_HERE" az:nvidia-575.vllm.0.9.0b python3 -m vllm.entrypoints.openai.api_server  --model /models/Qwen-Qwen3-32B-FP8     --max-model-len 8192     --served-model-name Qwen-Qwen3-32B-FP8